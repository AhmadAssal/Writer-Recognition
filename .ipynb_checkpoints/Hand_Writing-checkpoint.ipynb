{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, factor=1,name=\"image\"):\n",
    "    \"\"\" \n",
    "    show an image until the escape key is pressed\n",
    "    :param factor: scale factor (default 1, half size)\n",
    "    \"\"\"\n",
    "    if factor != 1.0:\n",
    "        img = cv2.resize(img, (0,0), fx=factor, fy=factor) \n",
    "\n",
    "    cv2.imshow(name,img)\n",
    "    while(1):\n",
    "        k = cv2.waitKey(0)\n",
    "        if k==27:    # Esc key to stop\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(input_path):\n",
    "    img = cv2.imread(input_path,0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,show_steps=1,show_size=0.2):\n",
    "    img = cv2.GaussianBlur(img,(11,11),0)\n",
    "    thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img[img >= thresh[0]] = 255\n",
    "    img[img <= thresh[0]] = 0\n",
    "    img = cv2.bitwise_not(img)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    if show_steps == 1:        \n",
    "        show(img,show_size,\"Preprocessed Image\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_top(img,show_steps=1,show_size=0.2):\n",
    "    trsh = 0.1\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion = cv2.dilate(img,kernel,iterations = 8)\n",
    "    proj = np.sum(erosion,axis=1).astype(int)\n",
    "    if show_steps == 1:        \n",
    "        show(erosion,show_size,\"Eroded\")\n",
    "    max_line = np.amax(proj)\n",
    "\n",
    "\n",
    "\n",
    "    lines = []\n",
    "    lines.append(300)\n",
    "    for i in range(img.shape[0]):\n",
    "        if(proj[i] >= trsh*max_line) :\n",
    "            if(len(lines) > 0 ):\n",
    "                if(lines[-1] + img.shape[0]/10 > i ):\n",
    "                    continue\n",
    "            if( (i>=500 and i <= 900) or (i>=2600 and i <= 2900)):\n",
    "                lines.append(i)\n",
    "    if show_steps == 1:        \n",
    "        show(img[lines[1]:lines[2],:],show_size,\"Cropped Image\")\n",
    "    \n",
    "    return img[lines[1]:lines[2],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(img,show_steps=1,show_size=0.2):\n",
    "    \n",
    "    original = img.copy()\n",
    "    blurred = cv2.GaussianBlur(img, (1, 1), 0)\n",
    "    canny = cv2.Canny(blurred, 50, 255, 1)\n",
    "    kernel = np.ones((1,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=40)\n",
    "    \n",
    "    if show_steps == 1:        \n",
    "        show(dilate,show_size,\"Sentences\")\n",
    "    \n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    image_number = 0\n",
    "    order_list = []\n",
    "    images = []\n",
    "    area = 0 \n",
    "    for c in cnts:\n",
    "        area += cv2.contourArea(c)\n",
    "    area /= (len(cnts)+5)\n",
    "    xarr = []\n",
    "    rxarr = []\n",
    "    yarr = []\n",
    "    ryarr = []\n",
    "    for c in cnts:\n",
    "        if(cv2.contourArea(c) > area):\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if h > img.shape[0]/8:\n",
    "                continue\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            ROI = original[y:y+h, x:x+w]\n",
    "            if show_steps == 1:        \n",
    "                show(ROI,show_size,\"Sentence\")\n",
    "            images.append(ROI)\n",
    "            order_list.append(y+x/1000)\n",
    "            image_number += 1\n",
    "    #print(max(xarr))\n",
    "    segments = [x for _,x in sorted(zip(order_list,images))]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel(img, center, x, y): \n",
    "      \n",
    "    new_value = 0\n",
    "      \n",
    "    try: \n",
    "        # If local neighbourhood pixel  \n",
    "        # value is greater than or equal \n",
    "        # to center pixel values then  \n",
    "        # set it to 1 \n",
    "        if img[x][y] >= center: \n",
    "            new_value = 1\n",
    "              \n",
    "    except: \n",
    "        # Exception is required when  \n",
    "        # neighbourhood value of a center \n",
    "        # pixel value is null i.e. values \n",
    "        # present at boundaries. \n",
    "        pass\n",
    "      \n",
    "    return new_value \n",
    "   \n",
    "# Function for calculating LBP \n",
    "def lbp_calculated_pixel(img, x, y): \n",
    "   \n",
    "    center = img[x][y] \n",
    "   \n",
    "    val_ar = [] \n",
    "      \n",
    "    # top_left \n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1)) \n",
    "      \n",
    "    # top \n",
    "    val_ar.append(get_pixel(img, center, x-1, y)) \n",
    "      \n",
    "    # top_right \n",
    "    val_ar.append(get_pixel(img, center, x-1, y + 1)) \n",
    "      \n",
    "    # right \n",
    "    val_ar.append(get_pixel(img, center, x, y + 1)) \n",
    "      \n",
    "    # bottom_right \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y + 1)) \n",
    "      \n",
    "    # bottom \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y)) \n",
    "      \n",
    "    # bottom_left \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y-1)) \n",
    "      \n",
    "    # left \n",
    "    val_ar.append(get_pixel(img, center, x, y-1)) \n",
    "       \n",
    "    # Now, we need to convert binary \n",
    "    # values to decimal \n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128] \n",
    "   \n",
    "    val = 0\n",
    "      \n",
    "    for i in range(len(val_ar)): \n",
    "        val += val_ar[i] * power_val[i] \n",
    "          \n",
    "    return val \n",
    "   \n",
    "\n",
    "def get_LBP(sentence,show_steps=1,show_size=0.2):\n",
    "\n",
    "    height, width = sentence.shape \n",
    "\n",
    "\n",
    "    # Create a numpy array as  \n",
    "    # the same height and width  \n",
    "    # of RGB image \n",
    "    img_lbp = np.zeros((height, width), np.uint8) \n",
    "\n",
    "    for i in range(0, height): \n",
    "        for j in range(0, width): \n",
    "            img_lbp[i, j] = lbp_calculated_pixel(sentence, i, j) \n",
    "    return img_lbp\n",
    "#img = get_LBP(sentences[0])\n",
    "#show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(image):\n",
    "    xarr = []\n",
    "    rxarr = []\n",
    "    yarr = []\n",
    "    ryarr = []\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        if (x != 0):\n",
    "            xarr.append(x)\n",
    "            rxarr.append(x+w)\n",
    "        if (y != 0):\n",
    "            yarr.append(y)\n",
    "            ryarr.append(y+h)\n",
    "        if h > img.shape[0]/8:\n",
    "            continue\n",
    "    args = [min(xarr), max(rxarr), min(yarr), max(ryarr)]\n",
    "    cropped = img[args[2]:args[3], args[0]:args[1]]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def divide(image):\n",
    "#     factor = 3\n",
    "#     rowInterval = image.shape[0]/3\n",
    "#     colInterval = image.shape[1]/3\n",
    "#     for i in range(0,factor):\n",
    "#         for j in range(0, factor):\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/resize.cpp:3935: error: (-215:Assertion failed) !dsize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-d699cface98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cropped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#contours, hierarchy = cv2.findContours(dilation.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-152ed9fee2b2>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(img, factor, name)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/resize.cpp:3935: error: (-215:Assertion failed) !dsize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "input_path = '/home/ahmad/Desktop/AlexRun/Pattern Recognition/Dataset/formsA-D/c02-026.png'\n",
    "show_steps = 0\n",
    "show_size = 0.2\n",
    "\n",
    "images = []\n",
    "#for file in os.listdir(input_path):\n",
    "#    images.append(file)\n",
    "#images.sort()\n",
    "#for input_img in images:    \n",
    "img = read_image(input_path)#+input_img)\n",
    "img = preprocess_img(img,show_steps,show_size)\n",
    "img = remove_top(img,show_steps,show_size)\n",
    "original = img\n",
    "kernel = np.ones((5,5))\n",
    "dilation = cv2.dilate(img,kernel,iterations = 20)\n",
    "sentences = get_sentences(img,show_steps,show_size)\n",
    "cropped = cropImage(dilation)\n",
    "#show(cropped, 0.2, \"Cropped\")\n",
    "# for sentence in sentences:\n",
    "#         contours, hierarchy = cv2.findContours(dilation.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         for contour in contours:\n",
    "#             x,y,w,h = cv2.boundingRect(contour)\n",
    "#             cv2.rectangle(sentence, (x, y), (x + w, y + h), (255,255,255), 2)\n",
    "#         show(contour, 0.2, \"Cropped\")\n",
    "\n",
    "#contours, hierarchy = cv2.findContours(dilation.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "#print(contours[0])\n",
    "\n",
    "#show(cropped, 0.3, \"cropped\")\n",
    "#imgplot = plt.imshow(cropped,cmap='gray')\n",
    "#plt.show()    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(original, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
