{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, factor=1,name=\"image\"):\n",
    "    \"\"\" \n",
    "    show an image until the escape key is pressed\n",
    "    :param factor: scale factor (default 1, half size)\n",
    "    \"\"\"\n",
    "    if factor != 1.0:\n",
    "        img = cv2.resize(img, (0,0), fx=factor, fy=factor) \n",
    "\n",
    "    cv2.imshow(name,img)\n",
    "    while(1):\n",
    "        k = cv2.waitKey(0)\n",
    "        if k==27:    # Esc key to stop\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(input_path):\n",
    "    img = cv2.imread(input_path,0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    mask_inv = img\n",
    "    ver_sum = np.sum(mask_inv,axis=1)\n",
    "    v_start = 0\n",
    "    v_end = 0\n",
    "    for i in range(len(ver_sum)):\n",
    "        if(ver_sum[i] > 0 and v_start ==0):\n",
    "            v_start = i\n",
    "        if(ver_sum[i] == 0 and v_start != 0):\n",
    "            v_end = i\n",
    "            break\n",
    "    if(v_end == 0):\n",
    "        v_end = len(ver_sum) - 1\n",
    "    \n",
    "    hor_sum = np.sum(mask_inv,axis=0)\n",
    "    h_start = 0\n",
    "    h_end = 0\n",
    "    for i in range(len(hor_sum)):\n",
    "        if(hor_sum[i] > 0 and h_start ==0):\n",
    "            h_start = i\n",
    "        if(hor_sum[i] == 0 and h_start != 0):\n",
    "            h_end = i\n",
    "            break\n",
    "    if(h_end == 0):\n",
    "        h_end = len(hor_sum) - 1\n",
    "\n",
    "    return img[v_start:v_end,h_start:h_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,show_steps=1,show_size=0.2):\n",
    "    img = cv2.GaussianBlur(img,(11,11),0)\n",
    "    thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img[img >= thresh[0]] = 255\n",
    "    img[img <= thresh[0]] = 0\n",
    "    img = cv2.bitwise_not(img)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    if show_steps == 1:        \n",
    "        show(img,show_size,\"Preprocessed Image\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_top(img,show_steps=1,show_size=0.2):\n",
    "    trsh = 0.1\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion = cv2.dilate(img,kernel,iterations = 8)\n",
    "    proj = np.sum(erosion,axis=1).astype(int)\n",
    "    if show_steps == 1:        \n",
    "        show(erosion,show_size,\"Eroded\")\n",
    "    max_line = np.amax(proj)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(300)\n",
    "    for i in range(img.shape[0]):\n",
    "        if(proj[i] >= trsh*max_line) :\n",
    "            if(len(lines) > 0 ):\n",
    "                if(lines[-1] + img.shape[0]/10 > i ):\n",
    "                    continue\n",
    "            if( (i>=500 and i <= 900) or (i>=2600 and i <= 2900)):\n",
    "                lines.append(i)\n",
    "    if show_steps == 1:        \n",
    "        show(img[lines[1]:lines[2],:],show_size,\"Cropped Image\")\n",
    "    \n",
    "    return img[lines[1]:lines[2],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lists(list1,list2):\n",
    "    list1 = np.asarray(list1)\n",
    "    sorter = np.argsort(list1)\n",
    "    list3 = []\n",
    "    for i in range(len(sorter)):\n",
    "        list3.append(list2[sorter[i]])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(img,show_steps=1,show_size=0.2):\n",
    "    \n",
    "    original = img.copy()\n",
    "    blurred = cv2.GaussianBlur(img, (1, 1), 0)\n",
    "    canny = cv2.Canny(blurred, 50, 255, 1)\n",
    "    kernel = np.ones((1,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=40)\n",
    "    \n",
    "    if show_steps == 1:        \n",
    "        show(dilate,show_size,\"Dialted for Sentence Extraction\")\n",
    "    \n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    image_number = 0\n",
    "    order_list = []\n",
    "    images = []\n",
    "    area = 0 \n",
    "    for c in cnts:\n",
    "        area += cv2.contourArea(c)\n",
    "    area /= (len(cnts)+5)\n",
    "    for c in cnts:\n",
    "        if(cv2.contourArea(c) > area and cv2.contourArea(c) < area*4):\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if h > img.shape[0]/8:\n",
    "                continue\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            ROI = original[y:y+h, x:x+w]\n",
    "            images.append(ROI)\n",
    "            order_list.append(y)\n",
    "    show(img,0.5)\n",
    "    segments = sort_lists(order_list,images)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_merge(sentence,show_steps=1,show_size=0.2):\n",
    "    try:\n",
    "        original = np.copy(sentence)\n",
    "\n",
    "        # Find contours\n",
    "        cnts = cv2.findContours(sentence, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        # Iterate thorugh contours and filter for ROI\n",
    "        order_list = []\n",
    "        images = []\n",
    "        area = 0 \n",
    "        for c in cnts:\n",
    "            area += cv2.contourArea(c)\n",
    "        area /= len(cnts)\n",
    "        for c in cnts:\n",
    "            if(cv2.contourArea(c) > area/5):\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                ROI = np.zeros((original.shape[0],w))\n",
    "                ROI[int(original.shape[0]/2-h/2):int(original.shape[0]/2+h/2),:] = original[y:y+h,x:x+w]\n",
    "                images.append(ROI)\n",
    "                order_list.append(x)\n",
    "\n",
    "        hori_merged = np.zeros((original.shape[0],original.shape[1]))\n",
    "\n",
    "        segments = sort_lists(order_list,images)\n",
    "        current = 0\n",
    "        for segment in segments:\n",
    "            hori_merged[:,current:current+segment.shape[1]] = segment\n",
    "            current = current+segment.shape[1]\n",
    "\n",
    "        hori_merged = crop_img(hori_merged)\n",
    "        if show_steps == 1:        \n",
    "            show(hori_merged,show_size*5,\"Sentence Horizontally Merge\")\n",
    "    except:\n",
    "        show(img,0.2,\"Error\")\n",
    "    return hori_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_image(image,show_steps=1,show_size=0.2):\n",
    "    \n",
    "    copy = np.zeros((image.shape[0], image.shape[1]))\n",
    "    sentences = get_sentences(image,show_steps,show_size)\n",
    "    contours, hierarchy = cv2.findContours(image.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    avg_height = 0\n",
    "    l = len(contours)\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        avg_height += h\n",
    "    avg_height = int(avg_height/l)\n",
    "    currentY = 150\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence = get_horizontal_merge(sentence,show_steps,show_size)\n",
    "        copy[currentY:currentY+sentence.shape[0],0:sentence.shape[1]] += sentence\n",
    "        currentY += int(avg_height/2)\n",
    "    copy = crop_img(copy)\n",
    "    if show_steps == 1:        \n",
    "        show(copy,show_size*5,\"Vertical Merge\")\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_image(image,show_steps=1,show_size=0.2):\n",
    "    factor = 3\n",
    "    height, width = image.shape\n",
    "    img_arr = []\n",
    "    w_3 =int(width/3)\n",
    "    h_3= int(height/3)\n",
    "    #first row\n",
    "    img_arr.append(image[0:h_3 , 0:w_3])\n",
    "    img_arr.append(image[0:h_3 , w_3:2*w_3])\n",
    "    img_arr.append(image[0:h_3 , 2*w_3:3*w_3])\n",
    "    \n",
    "    #second row\n",
    "    img_arr.append(image[h_3:2*h_3 , 0:w_3])\n",
    "    img_arr.append(image[h_3:2*h_3 , w_3:2*w_3])\n",
    "    img_arr.append(image[h_3:2*h_3 , 2*w_3:3*w_3])\n",
    "    \n",
    "    #third row\n",
    "    img_arr.append(image[2*h_3:3*h_3 , 0:w_3])\n",
    "    img_arr.append(image[2*h_3:3*h_3 , w_3:2*w_3])\n",
    "    img_arr.append(image[2*h_3:3*h_3 , 2*w_3:3*w_3])\n",
    "    if show_steps == 1:\n",
    "        for img in img_arr:\n",
    "            show(img,show_size*5,\"Texture Block\")\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel(img, center, x, y): \n",
    "      \n",
    "    new_value = 0\n",
    "      \n",
    "    try: \n",
    "        # If local neighbourhood pixel  \n",
    "        # value is greater than or equal \n",
    "        # to center pixel values then  \n",
    "        # set it to 1 \n",
    "        if img[x][y] >= center: \n",
    "            new_value = 1\n",
    "              \n",
    "    except: \n",
    "        # Exception is required when  \n",
    "        # neighbourhood value of a center \n",
    "        # pixel value is null i.e. values \n",
    "        # present at boundaries. \n",
    "        pass\n",
    "      \n",
    "    return new_value \n",
    "   \n",
    "# Function for calculating LBP \n",
    "def lbp_calculated_pixel(img, x, y): \n",
    "   \n",
    "    center = img[x][y] \n",
    "   \n",
    "    val_ar = [] \n",
    "      \n",
    "    # top_left \n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1)) \n",
    "      \n",
    "    # top \n",
    "    val_ar.append(get_pixel(img, center, x-1, y)) \n",
    "      \n",
    "    # top_right \n",
    "    val_ar.append(get_pixel(img, center, x-1, y + 1)) \n",
    "      \n",
    "    # right \n",
    "    val_ar.append(get_pixel(img, center, x, y + 1)) \n",
    "      \n",
    "    # bottom_right \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y + 1)) \n",
    "      \n",
    "    # bottom \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y)) \n",
    "      \n",
    "    # bottom_left \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y-1)) \n",
    "      \n",
    "    # left \n",
    "    val_ar.append(get_pixel(img, center, x, y-1)) \n",
    "       \n",
    "    # Now, we need to convert binary \n",
    "    # values to decimal \n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128] \n",
    "   \n",
    "    val = 0\n",
    "      \n",
    "    for i in range(len(val_ar)): \n",
    "        val += val_ar[i] * power_val[i] \n",
    "          \n",
    "    return val \n",
    "   \n",
    "\n",
    "def get_LBP(sentence,show_steps=1,show_size=0.2):\n",
    "\n",
    "    height, width = sentence.shape \n",
    "\n",
    "\n",
    "    # Create a numpy array as  \n",
    "    # the same height and width  \n",
    "    # of RGB image \n",
    "    img_lbp = np.zeros((height, width), np.uint8) \n",
    "\n",
    "    for i in range(0, height): \n",
    "        for j in range(0, width): \n",
    "            img_lbp[i, j] = lbp_calculated_pixel(sentence, i, j) \n",
    "    return img_lbp\n",
    "#img = get_LBP(sentences[0])\n",
    "#show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'F:/Tech/CUFE_CHS/Fall_2020/Pattern/Project/Data_Set/a02-000.png'\n",
    "show_steps = 1\n",
    "show_size = 0.2\n",
    "\n",
    "# images = []\n",
    "# for file in os.listdir(input_path):\n",
    "#     images.append(file)\n",
    "# images.sort()\n",
    "# for input_img in images:   \n",
    "#     print(input_img)\n",
    "#     img = read_image(input_path+input_img)\n",
    "img = read_image(input_path)#+input_img)\n",
    "img = preprocess_img(img,show_steps,show_size)\n",
    "img = remove_top(img,show_steps,show_size)\n",
    "large_texture_block = rearrange_image(img,show_steps,show_size)\n",
    "small_texture_blocks = divide_image(large_texture_block,show_steps,show_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(folder_name):\n",
    "    input_path = \"/media/madmax/MadMax_D/CUFE/Fall_2021/CMPN450_PatternRecognition_and_NeuralNetworks/Project document/Writer-Recognition/data/\" + folder_name + \"/\"\n",
    "    images = []\n",
    "    labeles=[]\n",
    "    # iterate over all 3 writers and add their feature vectors\n",
    "    for i in range(1, 4):\n",
    "        newpath = input_path + str(i) + \"/\"\n",
    "        for file in os.listdir(newpath):\n",
    "            images.append(cv2.imread(newpath + file))\n",
    "            labeles.append(i)\n",
    "\n",
    "    return images, labeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_count=10\n",
    "images = []\n",
    "lables=[]\n",
    "for test_cases in range (1,test_cases_count + 1):\n",
    "    folder_name = str(test_cases)\n",
    "    while len(folder_name)<2:\n",
    "        folder_name = \"0\" + folder_name\n",
    "    images_temp,lables_temp = training_data(folder_name)\n",
    "    images.append(images_temp)\n",
    "    lables.append(lables_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
