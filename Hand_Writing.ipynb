{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from skimage import feature\n",
    "from skimage.exposure import histogram\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import LinearSVC\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import time\n",
    "import glob,fnmatch\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, factor=1,name=\"image\"):\n",
    "    \"\"\" \n",
    "    show an image until the escape key is pressed\n",
    "    :param factor: scale factor (default 1, half size)\n",
    "    \"\"\"\n",
    "    if factor != 1.0:\n",
    "        img = cv2.resize(img, (0,0), fx=factor, fy=factor) \n",
    "\n",
    "    cv2.imshow(name,img)\n",
    "    while(1):\n",
    "        k = cv2.waitKey(0)\n",
    "        if k==27:    # Esc key to stop\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(input_path):\n",
    "    img = cv2.imread(input_path,0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    mask_inv = img\n",
    "    ver_sum = np.sum(mask_inv,axis=1)\n",
    "    v_start = 0\n",
    "    v_end = 0\n",
    "    for i in range(len(ver_sum)):\n",
    "        if(ver_sum[i] > 0 and v_start ==0):\n",
    "            v_start = i\n",
    "        if(ver_sum[i] == 0 and v_start != 0):\n",
    "            v_end = i\n",
    "            break\n",
    "    if(v_end == 0):\n",
    "        v_end = len(ver_sum) - 1\n",
    "    \n",
    "    hor_sum = np.sum(mask_inv,axis=0)\n",
    "    h_start = 0\n",
    "    h_end = 0\n",
    "    for i in range(len(hor_sum)):\n",
    "        if(hor_sum[i] > 0 and h_start ==0):\n",
    "            h_start = i\n",
    "        if(hor_sum[i] == 0 and h_start != 0):\n",
    "            h_end = i\n",
    "            break\n",
    "    if(h_end == 0):\n",
    "        h_end = len(hor_sum) - 1\n",
    "\n",
    "    return img[v_start:v_end,h_start:h_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,show_steps=1,show_size=0.2):\n",
    "    img = cv2.GaussianBlur(img,(11,11),0)\n",
    "    thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img[img >= thresh[0]] = 255\n",
    "    img[img <= thresh[0]] = 0\n",
    "    img = cv2.bitwise_not(img)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    if show_steps == 1:        \n",
    "        show(img,show_size,\"Preprocessed Image\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_top(binary_img,gray_img,show_steps=1,show_size=0.2):\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    y_list = []\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if w > binary_img.shape[1] / 2 and w < binary_img.shape[1] * 5 / 6:\n",
    "            y_list.append(y)\n",
    "    y_list = np.sort(y_list)\n",
    "    y1=y_list[-2]\n",
    "    y2=y_list[-1]\n",
    "    if show_steps == 1:        \n",
    "        show(gray_img[y1+20:y2-20,:],show_size,\"Cropped Image\")\n",
    "    return binary_img[y1+20:y2-20,:],gray_img[y1+20:y2-20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lists(list1,list2):\n",
    "    list1 = np.asarray(list1)\n",
    "    sorter = np.argsort(list1)\n",
    "    list3 = []\n",
    "    for i in range(len(sorter)):\n",
    "        list3.append(list2[sorter[i]])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(boxes,max_h):\n",
    "    i = 0\n",
    "    while i < len(boxes)-1:\n",
    "        j = i+1\n",
    "        while j < len(boxes):\n",
    "            x1,y1,w1,h1 = (boxes[i])[0],(boxes[i])[1],(boxes[i])[2],(boxes[i])[3]\n",
    "            x2,y2,w2,h2 = (boxes[j])[0],(boxes[j])[1],(boxes[j])[2],(boxes[j])[3]\n",
    "            if x2 < x1+w1:\n",
    "                boxes[i] = [x1,min(y1,y2),x2+w2-x1,max(y1+h1,y2+h2)-min(y1,y2)]\n",
    "                del boxes[j]\n",
    "            else:\n",
    "                break\n",
    "        i += 1\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_block(binary_img,gray_img,show_steps,show_size):\n",
    "\n",
    "    original_binary = binary_img.copy()\n",
    "    original_gray = gray_img.copy()       \n",
    "    if show_steps == 1:        \n",
    "        show(binary_img,show_size,\"Block Separation\")\n",
    "    \n",
    "    cnts,_ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    avg_h = 0\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        avg_h += h\n",
    "    avg_h /= len(cnts)\n",
    "    avg_h *= 1.75\n",
    "    b_sents = []\n",
    "    g_sents = []\n",
    "    \n",
    "    hor_sum = np.sum(binary_img, axis=1)\n",
    "    max_line = np.amax(hor_sum)\n",
    "    h_c = 0\n",
    "    for i in range(len(hor_sum)):\n",
    "        h_c += 1\n",
    "        if(h_c > avg_h and hor_sum[i] < 0.4*max_line):\n",
    "            if( (i-avg_h) >avg_h and np.sum(original_binary[int(i-avg_h):i,:]) > 0.05*255*original_binary[int(i-avg_h):i,:].shape[0]*original_binary[int(i-avg_h):i,:].shape[1]):\n",
    "                b_sents.append(original_binary[int(i-avg_h):i,:])\n",
    "                g_sents.append(original_gray[int(i-avg_h):i,:])\n",
    "                if show_steps == 1:        \n",
    "                    show(original_gray[int(i-avg_h):i,:],1,\"Separated Block Number : \" + str(len(b_sents)))\n",
    "                h_c = 0\n",
    "            \n",
    "    \n",
    "    return b_sents,g_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(binary_img,gray_img,show_steps=1,show_size=0.2):\n",
    "    \n",
    "    original_binary = binary_img.copy()\n",
    "    original_gray = gray_img.copy()    \n",
    "    canny = cv2.Canny(binary_img, 200, 400)\n",
    "    kernel = np.ones((1,7),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=40)\n",
    "    \n",
    "    if show_steps == 1:        \n",
    "        show(dilate,show_size,\"Dialted for Sentence Extraction\")\n",
    "    \n",
    "    # Find contours\n",
    "    cnts,_ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    image_number = 0\n",
    "    order_list = []\n",
    "    binary_images = []\n",
    "    gray_images = []\n",
    "    area = 0 \n",
    "    for c in cnts:\n",
    "        area += cv2.contourArea(c)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "    area /= (len(cnts))\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if cv2.contourArea(c) > area/2:\n",
    "\n",
    "            if (w < binary_img.shape[0]/5)  or (h > binary_img.shape[0]/6 and w < binary_img.shape[0]/5):\n",
    "                continue\n",
    "            cv2.rectangle(binary_img, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            ROI_binary = original_binary[y:y+h, x:x+w]\n",
    "            ROI_gray = original_gray[y:y+h, x:x+w]\n",
    "\n",
    "            if h > binary_img.shape[0]/7:\n",
    "                b_sents,g_sents = split_block(ROI_binary,ROI_gray,show_steps,show_size)\n",
    "                for i in range(len(b_sents)):\n",
    "                    order_list.append(y+ (i/len(b_sents))*h )\n",
    "                    binary_images.append(b_sents[i])\n",
    "                    gray_images.append(g_sents[i])\n",
    "            else:\n",
    "                binary_images.append(ROI_binary)\n",
    "                gray_images.append(ROI_gray)\n",
    "                order_list.append(y)\n",
    "\n",
    "    sentences_binary = sort_lists(order_list,binary_images)\n",
    "    sentences_gray = sort_lists(order_list,gray_images)\n",
    "    return sentences_binary,sentences_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_merge(binary_sentence,gray_sentence,show_steps=1,show_size=0.2):\n",
    "    original = (gray_sentence*(binary_sentence/255)).astype(np.uint8)\n",
    "    if show_steps == 1:        \n",
    "        show(original,show_size*2,\"Sentence Before Horizontal Merge\")\n",
    "    # Find contours\n",
    "    cnts,_ = cv2.findContours(binary_sentence, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    order_list = []\n",
    "    boxes = []\n",
    "    images = []\n",
    "    area = 0 \n",
    "    avg_height = 0\n",
    "    for c in cnts:\n",
    "        area += cv2.contourArea(c)\n",
    "    area /= len(cnts)\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if cv2.contourArea(c) > area/8 :\n",
    "            boxes.append([x,y,w,h])\n",
    "            order_list.append(x)\n",
    "        else:\n",
    "            original[y:y+h,x:x+w] = 0\n",
    "    boxes = sort_lists(order_list,boxes)\n",
    "    boxes = merge_boxes(boxes,original.shape[0])\n",
    "    for box in boxes:\n",
    "        x,y,w,h = box[0],box[1],box[2],box[3]                    \n",
    "        ROI = np.zeros((original.shape[0],w))\n",
    "        avg_height += h\n",
    "        if int(original.shape[0]/2-h/2) > 0 :\n",
    "            ROI[int(original.shape[0]/2-h/2):int(original.shape[0]/2-h/2)+h,:] = original[y:y+h,x:x+w]\n",
    "        else:           \n",
    "            ROI[0:h,:] = original[y:y+h,x:x+w]\n",
    "        images.append(ROI)\n",
    "    avg_height /= len(boxes)\n",
    "    hori_merged = np.zeros((original.shape[0],original.shape[1]))\n",
    "    current = 0\n",
    "    for image in images:\n",
    "        hori_merged[:,current:current+image.shape[1]] += image\n",
    "        current = current+image.shape[1]\n",
    "    hori_merged = crop_img(hori_merged)\n",
    "    hori_merged = hori_merged.astype(np.uint8)\n",
    "    if show_steps == 1:        \n",
    "        show(hori_merged,show_size*5,\"Sentence After Horizontal Merge\")\n",
    "\n",
    "    return hori_merged,avg_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_image(binary_img,gray_img,show_steps=1,show_size=0.2):\n",
    "    \n",
    "    copy = np.zeros((binary_img.shape[0], binary_img.shape[1]))\n",
    "    binary_sentences,gray_sentences = get_sentences(binary_img,gray_img,show_steps,show_size)\n",
    "    contours, hierarchy = cv2.findContours(binary_img.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    currentY = 150\n",
    "    for i in range(len(binary_sentences)):\n",
    "        \n",
    "        sentence,avg_height = get_horizontal_merge(binary_sentences[i],gray_sentences[i],show_steps,show_size)\n",
    "        ROI = copy[currentY:currentY+sentence.shape[0],0:sentence.shape[1]]\n",
    "#         ROI += sentence\n",
    "        ROI[ROI == 0] = sentence[ROI == 0]\n",
    "        copy[currentY:currentY+sentence.shape[0],0:sentence.shape[1]] += ROI\n",
    "        currentY += int(avg_height/2)\n",
    "    copy = crop_img(copy)\n",
    "    copy = copy.astype(np.uint8)\n",
    "    if show_steps == 1:        \n",
    "        show(copy,show_size*2,\"Vertical Merge\")\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_image(image,show_steps=1,show_size=0.2):\n",
    "    factor = 3\n",
    "    height, width = image.shape\n",
    "    img_arr = []\n",
    "    w_3 =int(width/3)\n",
    "    h_3= int(height/3)\n",
    "\n",
    "    for i in range(9):\n",
    "        rand_row = int((random.random()*image.shape[0]) %(image.shape[0] - 128))\n",
    "        ran_column = int((random.random()*image.shape[1]) %(image.shape[1] - 256))\n",
    "#         img_arr.append(image[rand_row:rand_row+128 , ran_column:ran_column+256])\n",
    "        img_arr.append( image[int(image.shape[0]/2 - 64):int(image.shape[0]/2 + 64) , ran_column:ran_column+256])\n",
    "\n",
    "    if show_steps == 1:\n",
    "        for img in img_arr:\n",
    "            show(img,show_size*2,\"Texture Block\")\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel(img, center, x, y): \n",
    "      \n",
    "    new_value = 0\n",
    "      \n",
    "    try: \n",
    "        # If local neighbourhood pixel  \n",
    "        # value is greater than or equal \n",
    "        # to center pixel values then  \n",
    "        # set it to 1 \n",
    "        if img[x][y] >= center: \n",
    "            new_value = 1\n",
    "              \n",
    "    except: \n",
    "        # Exception is required when  \n",
    "        # neighbourhood value of a center \n",
    "        # pixel value is null i.e. values \n",
    "        # present at boundaries. \n",
    "        pass\n",
    "      \n",
    "    return new_value \n",
    "   \n",
    "# Function for calculating LBP \n",
    "def lbp_calculated_pixel(img, x, y): \n",
    "   \n",
    "    center = img[x][y] \n",
    "   \n",
    "    val_ar = [] \n",
    "      \n",
    "    # top_left \n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1)) \n",
    "      \n",
    "    # top \n",
    "    val_ar.append(get_pixel(img, center, x-1, y)) \n",
    "      \n",
    "    # top_right \n",
    "    val_ar.append(get_pixel(img, center, x-1, y + 1)) \n",
    "      \n",
    "    # right \n",
    "    val_ar.append(get_pixel(img, center, x, y + 1)) \n",
    "      \n",
    "    # bottom_right \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y + 1)) \n",
    "      \n",
    "    # bottom \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y)) \n",
    "      \n",
    "    # bottom_left \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y-1)) \n",
    "      \n",
    "    # left \n",
    "    val_ar.append(get_pixel(img, center, x, y-1)) \n",
    "       \n",
    "    # Now, we need to convert binary \n",
    "    # values to decimal \n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128] \n",
    "   \n",
    "    val = 0\n",
    "      \n",
    "    for i in range(len(val_ar)): \n",
    "        val += val_ar[i] * power_val[i] \n",
    "          \n",
    "    return val \n",
    "   \n",
    "\n",
    "def get_LBP(sentence,show_steps=1,show_size=0.2):\n",
    "\n",
    "    height, width = sentence.shape \n",
    "\n",
    "\n",
    "    # Create a numpy array as  \n",
    "    # the same height and width  \n",
    "    # of RGB image \n",
    "    img_lbp = np.zeros((height, width), np.uint8) \n",
    "\n",
    "    for i in range(0, height): \n",
    "        for j in range(0, width): \n",
    "            img_lbp[i, j] = lbp_calculated_pixel(sentence, i, j) \n",
    "    return img_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "    def __init__(self,nbins=256):\n",
    "        self.nbins = nbins\n",
    "    def describe(self, image):\n",
    "\n",
    "        lbp = get_LBP(image)\n",
    "        H = np.zeros(self.nbins)\n",
    "        # Step (b) calculate histogram of the image\n",
    "        for  i in range (lbp.shape[0]):\n",
    "            for  j in range (lbp.shape[1]):\n",
    "                H[(lbp[i][j])] += 1\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory(input_path):\n",
    "    cases = []\n",
    "    for file in os.listdir(input_path):\n",
    "        cases.append(file)\n",
    "    cases = sorted(cases)\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(clf,input_path,case,show_steps=1,show_size=0.2):\n",
    "    desc = LocalBinaryPatterns(256)\n",
    "    data = []\n",
    "    gray_img = read_image(input_path+case+\"/test\"+type_image)\n",
    "    start = time.time()\n",
    "    #print(input_path+case+\"/test.png\")\n",
    "    binary_img = preprocess_img(gray_img,show_steps,show_size)\n",
    "    binary_img,gray_img = remove_top(binary_img,gray_img,show_steps,show_size)\n",
    "    large_texture_block = rearrange_image(binary_img,gray_img,show_steps,show_size)\n",
    "    blocks = divide_image(large_texture_block,show_steps,show_size)\n",
    "    for block in blocks:\n",
    "        hist = desc.describe(block)\n",
    "        data.append(hist)\n",
    "    end = time.time()\n",
    "    return np.bincount(np.around(clf.predict(data)).astype(int)).argmax(),end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_path,case,show_steps=1,show_size=0.2):\n",
    "    desc = LocalBinaryPatterns(256)\n",
    "    data = []\n",
    "    labels = []\n",
    "    total_time = 0\n",
    "    for i in range(3):\n",
    "        for  j in range(2):\n",
    "            print(input_path+case+\"/\"+str(i+1)+\"/\"+str(j+1)+type_image)\n",
    "            gray_img = read_image(input_path+case+\"/\"+str(i+1)+\"/\"+str(j+1)+type_image)\n",
    "            start = time.time()\n",
    "            binary_img = preprocess_img(gray_img,show_steps,show_size)\n",
    "            binary_img,gray_img = remove_top(binary_img,gray_img,show_steps,show_size)\n",
    "            large_texture_block = rearrange_image(binary_img,gray_img,show_steps,show_size)\n",
    "            blocks = divide_image(large_texture_block,show_steps,show_size)\n",
    "            for block in blocks:\n",
    "                hist = desc.describe(block)\n",
    "                labels.append(i+1)\n",
    "                data.append(hist)\n",
    "            end = time.time()\n",
    "            total_time += end-start\n",
    "    \n",
    "    start = time.time()    \n",
    "    model =  LinearSVC(C=300, random_state=42,max_iter=2000000000)\n",
    "    model.fit(data, labels)\n",
    "    end = time.time()\n",
    "    total_time += end-start\n",
    "    return model,total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(classification, input_path, case, errors_log):\n",
    "    f = open(input_path+ case + \"/truth.txt\", \"r\")\n",
    "    \n",
    "    result = int(f.read())\n",
    "    f.close()\n",
    "    if result == classification:\n",
    "        return True\n",
    "    else:\n",
    "        errors_log.write(\"Wrong classification at case : \" + case + \"\\n\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test Case  0\n",
      "data/00/1/1.JPG\n",
      "data/00/1/2.JPG\n",
      "data/00/2/1.JPG\n",
      "data/00/2/2.JPG\n",
      "data/00/3/1.JPG\n",
      "data/00/3/2.JPG\n",
      "Running Test Case  1\n",
      "data/01/1/1.JPG\n",
      "data/01/1/2.JPG\n",
      "data/01/2/1.JPG\n",
      "data/01/2/2.JPG\n",
      "data/01/3/1.JPG\n",
      "data/01/3/2.JPG\n"
     ]
    }
   ],
   "source": [
    "input_path = \"data/\"\n",
    "show_steps = 0\n",
    "show_size = 0.2\n",
    "random.seed(1)\n",
    "cases = read_directory(input_path)\n",
    "classifications = open(\"results.txt\", \"w\")\n",
    "errors_log = open(\"error.log\", \"w\")\n",
    "timing = open(\"time.txt\", \"w\")\n",
    "for i, case in enumerate(cases):\n",
    "    try :\n",
    "        print(\"Running Test Case \", i)\n",
    "        total_time = 0\n",
    "        case = str(case)\n",
    "        clf,train_time = train(input_path,case,show_steps,show_size)\n",
    "        total_time += train_time\n",
    "        y,test_time = classify(clf,input_path,case,show_steps,show_size)\n",
    "        total_time +=  test_time\n",
    "        timing.write(str(round(total_time,2))+\"\\n\")\n",
    "        classifications.write(str(y)+\"\\n\")\n",
    "        #acc_list.append(calculate_accuracy(y, input_path, case,errors_log))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        y = int((int(random.random()*100) % 3) + 1)\n",
    "        classifications.write(str(y)+\"\\n\")\n",
    "        errors_log.write(\"Exception at case : \" + case + \"\\n\")\n",
    "    #acc_list = np.array(acc_list)\n",
    "    #print(\"Accuracy: \", (len(acc_list[acc_list == True])/ len(acc_list)) * 100, \"%\")\n",
    "classifications.close()\n",
    "errors_log.close()\n",
    "timing.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_forms_data():\n",
    "    \"\"\"\n",
    "    this function read the forms.txt and extract the writer id and the form id that he wrote it.\n",
    "    :return: dictionary of writers and the form that he has  written  key= form_id and value = writer_id\n",
    "    \"\"\"\n",
    "    writers = {}\n",
    "    reader = open(path_forms_txt)\n",
    "    inputs = list(reader)\n",
    "    for line in inputs:\n",
    "        form_info = line.split(' ')\n",
    "        if \"#\" not in form_info[0]:\n",
    "            form_id = form_info[0]\n",
    "            writer_id = form_info[1]\n",
    "            writers[form_id] = writer_id\n",
    "\n",
    "    return writers\n",
    "\n",
    "\n",
    "def order_data_set():\n",
    "    \"\"\"\n",
    "    this function call the read_forms_data() and collect all the forms written by the same author in one folder\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    writers_set = read_forms_data()\n",
    "    for form in writers_set:\n",
    "        new_path_data += str(writers_set[form])\n",
    "        form_name = str(form) + type_image\n",
    "        if not os.path.exists(new_path_data):\n",
    "            os.makedirs(new_path_data)\n",
    "            os.rename(old_path_data + form_name,\n",
    "                      new_path_data + '/' + form_name)\n",
    "        else:\n",
    "            os.rename(old_path_data + form_name,\n",
    "                      new_path_data + '/' + form_name)\n",
    "\n",
    "    return\n",
    "order_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter():\n",
    "    suitable = []\n",
    "    for filename in os.listdir(path_filter):\n",
    "        i = len(os.listdir(path_filter + \"/\" + filename))\n",
    "        if (i >= 3):\n",
    "            suitable.append(filename)\n",
    "    suitable.sort()\n",
    "    #print(suitable)\n",
    "    return suitable,path_filter\n",
    "\n",
    "\n",
    "def generate_random_test_cases(num):\n",
    "    new_path_testcases=path_place_testcases + str(num) + \"/\"\n",
    "    os.makedirs(new_path_testcases)\n",
    "    suitable, dataset_path = filter()\n",
    "    random.seed(datetime.now())\n",
    "    random_choices = random.sample(suitable, 3)\n",
    "    \n",
    "    rand_index = random.randrange(0,3)\n",
    "    test_images = []\n",
    "    for i, choice in enumerate(random_choices):\n",
    "        this_path = new_path_testcases + str(i+1)\n",
    "        os.makedirs(this_path)\n",
    "        images = os.listdir(dataset_path + \"/\" + choice)\n",
    "        random_images = random.sample(images, 3)\n",
    "        \n",
    "        for i in range(2):\n",
    "            shutil.copy2(dataset_path + \"/\" + choice + \"/\" +  random_images[i] , this_path)\n",
    "            os.rename(this_path + \"/\" + random_images[i], this_path + \"/\" + str(i + 1) + type_image)\n",
    "        test_images.append(dataset_path + \"/\" + choice + \"/\"+ random_images[2])\n",
    "    shutil.copy2(test_images[rand_index] , new_path_testcases)\n",
    "    os.chdir(new_path_testcases)\n",
    "    for file in glob.glob(\"*\"+type_image):\n",
    "        os.rename(new_path_testcases + \"/\"+ file, \"test\"+ type_image)\n",
    "\n",
    "    f = open(new_path_testcases + \"truth.txt\", \"w\")\n",
    "    f.write(str(rand_index + 1))\n",
    "    f.close()\n",
    "    print(\"Test case \" + str(num) + \" generated!\")\n",
    "    print(\"Truth is \" + str(rand_index + 1))\n",
    "\n",
    "for i in range(400):\n",
    "    generate_random_test_cases(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
